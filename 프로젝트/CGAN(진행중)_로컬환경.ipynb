{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization\n",
    "from keras.layers import Input, Flatten, Embedding, multiply, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Reshape, Flatten\n",
    "from keras.layers import Input, Flatten, Embedding, multiply, Dropout\n",
    "from keras.layers import Concatenate, GaussianNoise,Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras import initializers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.03776023 -0.00824963]\n",
      "  [-0.04877186  0.030853  ]\n",
      "  [-0.01231469 -0.04367311]\n",
      "  [-0.04678584  0.04472027]\n",
      "  [ 0.02257991  0.02617644]\n",
      "  [ 0.02229757 -0.01649895]\n",
      "  [ 0.024586   -0.02258464]\n",
      "  [ 0.03942456 -0.01603343]\n",
      "  [ 0.04727579  0.00072814]\n",
      "  [ 0.01355512 -0.03978248]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1358a435a30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10, 2))\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "\n",
    "# input_array = np.random.randint(10, size=(1, 10))\n",
    "input_array = np.arange(0, 10).reshape(1, -1)\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array)\n",
    "# print(output_array.shape)\n",
    "plt.scatter(output_array[0, :, 0], output_array[0, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'CGAN-only_1000' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/kyk0325v/CGAN-only_1000.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "batch_size = 40000 \n",
    "\n",
    "images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "obj = generator.flow_from_directory(\n",
    "    'C:/Users/4/Downloads/CGAN-only_1000',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary')\n",
    " \n",
    " \n",
    "    # for i in enumerate(range(iterations)):\n",
    "#     img, label = obj .next()\n",
    "#     n_img = len(label)\n",
    "    \n",
    "#     base = cv2.cvtColor(img[0], cv2.COLOR_RGB2BGR)  # keras는 RGB, openCV는 BGR이라 변경함\n",
    "#     for idx in range(n_img - 1):\n",
    "#         img2 = cv2.cvtColor(img[idx + 1], cv2.COLOR_RGB2BGR)\n",
    "#         base = np.hstack((base, img2))\n",
    "#     images.append(base)\n",
    " \n",
    "# img = images[0]\n",
    "# for idx in range(len(images) - 1):\n",
    "#     img = np.vstack((img, images[idx + 1]))\n",
    "# cv2.imshow('result', img) #Colored by Color Scripter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = next(obj)[0]\n",
    "y_train = next(obj)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "    new = y_train[i] - 1\n",
    "    y_train[i] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "print(num_classes)\n",
    "\n",
    "class_names = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train reshape: (9000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "#Y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "X_train = np.float32(X_train)\n",
    "X_train = (X_train / 255 - 0.5) * 2\n",
    "X_train = np.clip(X_train, -1, 1)\n",
    "\n",
    "print('X_train reshape:', X_train.shape)\n",
    "#print('Y_train reshape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 109)          0           input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         225280      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 2048)         8192        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 2048)         0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 2, 2, 512)    0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 4, 4, 256)    3277056     reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 4, 4, 256)    1024        conv2d_transpose_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 4, 4, 256)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 8, 8, 128)    819328      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 128)    512         conv2d_transpose_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 8, 8, 128)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 16, 16, 64)   204864      leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 64)   256         conv2d_transpose_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 16, 16, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 32, 32, 32)   51232       leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 32)   128         conv2d_transpose_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 32, 32, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 64, 64, 3)    2403        leaky_re_lu_25[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 4,590,275\n",
      "Trainable params: 4,585,219\n",
      "Non-trainable params: 5,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# latent space dimension\n",
    "z = Input(shape=(100,))\n",
    "\n",
    "# classes\n",
    "labels = Input(shape=(9,))\n",
    "\n",
    "# Generator network\n",
    "merged_layer = Concatenate()([z, labels])\n",
    "\n",
    "# FC: 2x2x512\n",
    "generator = Dense(2*2*512, activation='relu')(merged_layer)\n",
    "generator = BatchNormalization(momentum=0.9)(generator)\n",
    "generator = LeakyReLU(alpha=0.1)(generator)\n",
    "generator = Reshape((2, 2, 512))(generator)\n",
    "\n",
    "# # Conv 1: 4x4x256\n",
    "generator = Conv2DTranspose(256, kernel_size=5, strides=2, padding='same')(generator)\n",
    "generator = BatchNormalization(momentum=0.9)(generator)\n",
    "generator = LeakyReLU(alpha=0.1)(generator)\n",
    "\n",
    "# Conv 2: 8x8x128\n",
    "generator = Conv2DTranspose(128, kernel_size=5, strides=2, padding='same')(generator)\n",
    "generator = BatchNormalization(momentum=0.9)(generator)\n",
    "generator = LeakyReLU(alpha=0.1)(generator)\n",
    "\n",
    "# Conv 3: 16x16x64\n",
    "generator = Conv2DTranspose(64, kernel_size=5, strides=2, padding='same')(generator)\n",
    "generator = BatchNormalization(momentum=0.9)(generator)\n",
    "generator = LeakyReLU(alpha=0.1)(generator)\n",
    "\n",
    "# Conv 4: 32x32x3\n",
    "generator = Conv2DTranspose(32, kernel_size=5, strides=2, padding='same')(generator)\n",
    "generator = BatchNormalization(momentum=0.9)(generator)\n",
    "generator = LeakyReLU(alpha=0.1)(generator)\n",
    "\n",
    "# Conv 4: 64x64x3\n",
    "generator = Conv2DTranspose(3, kernel_size=5, strides=2, padding='same', activation='tanh')(generator)\n",
    "\n",
    "# generator = Model(inputs=[z, labels], outputs=out_g)\n",
    "generator = Model(inputs=[z, labels], outputs=generator, name='generator')\n",
    "\n",
    "# prints a summary representation of your model\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 64)   4864        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 32, 32, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 128)  204928      leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 16, 16, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 256)    819456      leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 8, 8, 256)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 512)    3277312     leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 4, 512)    2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 4, 4, 512)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 8192)         0           leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8201)         0           flatten_3[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          4199424     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            513         dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,510,337\n",
      "Trainable params: 8,508,417\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input image\n",
    "img_input = Input(shape=(X_train[0].shape))\n",
    "\n",
    "# Conv 1: 16x16x64\n",
    "discriminator = Conv2D(32, kernel_size=5, strides=2, padding='same')(img_input)\n",
    "discriminator = BatchNormalization(momentum=0.9)(discriminator)\n",
    "discriminator = LeakyReLU(alpha=0.1)(discriminator)\n",
    "\n",
    "# Conv 1: 16x16x64\n",
    "discriminator = Conv2D(64, kernel_size=5, strides=2, padding='same')(img_input)\n",
    "discriminator = BatchNormalization(momentum=0.9)(discriminator)\n",
    "discriminator = LeakyReLU(alpha=0.1)(discriminator)\n",
    "\n",
    "# Conv 2:\n",
    "discriminator = Conv2D(128, kernel_size=5, strides=2, padding='same')(discriminator)\n",
    "discriminator = BatchNormalization(momentum=0.9)(discriminator)\n",
    "discriminator = LeakyReLU(alpha=0.1)(discriminator)\n",
    "\n",
    "# Conv 3: \n",
    "discriminator = Conv2D(256, kernel_size=5, strides=2, padding='same')(discriminator)\n",
    "discriminator = BatchNormalization(momentum=0.9)(discriminator)\n",
    "discriminator = LeakyReLU(alpha=0.1)(discriminator)\n",
    "\n",
    "# Conv 4: \n",
    "discriminator = Conv2D(512, kernel_size=5, strides=2, padding='same')(discriminator)\n",
    "discriminator = BatchNormalization(momentum=0.9)(discriminator)\n",
    "discriminator = LeakyReLU(alpha=0.1)(discriminator)\n",
    "\n",
    "# FC\n",
    "discriminator = Flatten()(discriminator)\n",
    "\n",
    "# Concatenate \n",
    "merged_layer = Concatenate()([discriminator, labels])\n",
    "discriminator = Dense(512, activation='relu')(merged_layer)\n",
    "    \n",
    "# Output\n",
    "discriminator = Dense(1, activation='sigmoid')(discriminator)\n",
    "\n",
    "discriminator = Model(inputs=[img_input, labels], outputs=discriminator, name='discriminator')\n",
    "\n",
    "\n",
    "# prints a summary representation of your model\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimizer\n",
    "discriminator.compile(Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy',\n",
    "                      metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"adversarial\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "z (InputLayer)                  (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label (InputLayer)              (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator (Model)               (None, 64, 64, 3)    4590275     z[0][0]                          \n",
      "                                                                 label[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "discriminator (Model)           (None, 1)            8510337     generator[1][0]                  \n",
      "                                                                 label[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 13,100,612\n",
      "Trainable params: 4,585,219\n",
      "Non-trainable params: 8,515,393\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "label = Input(shape=(9,), name='label')\n",
    "z = Input(shape=(100,), name='z')\n",
    "\n",
    "fake_img = generator([z, label])\n",
    "validity = discriminator([fake_img, label])\n",
    "\n",
    "d_g = Model([z, label], validity, name='adversarial')\n",
    "\n",
    "d_g.compile(Adam(lr=0.0004, beta_1=0.5), loss='binary_crossentropy',\n",
    "            metrics=['binary_accuracy'])\n",
    "\n",
    "# prints a summary representation of your model\n",
    "d_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels = to_categorical(y_train[i*batch_size:(i+1)*batch_size].reshape(-1, 1), num_classes=9)\n",
    "real_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1/300, batch = 5/140, d_loss=0.327, g_loss=0.352                                                                                                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-5b8920f2b3cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mrandom_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0md_g_loss_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_labels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         print(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \"\"\"\n\u001b[1;32m-> 1605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "batch_size = 64\n",
    "smooth = 0.1\n",
    "latent_dim = 100\n",
    "\n",
    "real = np.ones(shape=(batch_size, 1))\n",
    "fake = np.zeros(shape=(batch_size, 1))\n",
    "\n",
    "d_loss = []\n",
    "d_g_loss = []\n",
    "\n",
    "for e in range(epochs + 1):\n",
    "    \n",
    "    for i in range(len(X_train) // batch_size):\n",
    "        \n",
    "        # Train Discriminator weights\n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        # Real samples\n",
    "        X_batch = X_train[i*batch_size:(i+1)*batch_size]\n",
    "        real_labels = to_categorical(y_train[i*batch_size:(i+1)*batch_size].reshape(-1, 1), num_classes=9)\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch(x=[X_batch, real_labels],\n",
    "                                                   y=real * (1 - smooth))\n",
    "        \n",
    "        # Fake Samples\n",
    "        z = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n",
    "        random_labels = to_categorical(np.random.randint(0, 9, batch_size).reshape(-1, 1), num_classes=9)\n",
    "        X_fake = generator.predict_on_batch([z, random_labels])\n",
    "        \n",
    "        d_loss_fake = discriminator.train_on_batch(x=[X_fake, random_labels], y=fake)\n",
    "         \n",
    "        # Discriminator loss\n",
    "        d_loss_batch = 0.5 * (d_loss_real[0] + d_loss_fake[0])\n",
    "        \n",
    "        # Train Generator weights\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        z = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n",
    "        random_labels = to_categorical(np.random.randint(0, 9, batch_size).reshape(-1, 1), num_classes=9)\n",
    "        d_g_loss_batch = d_g.train_on_batch(x=[z, random_labels], y=real)\n",
    "   \n",
    "        print(\n",
    "            'epoch = %d/%d, batch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, i, len(X_train) // batch_size, d_loss_batch, d_g_loss_batch[0]),\n",
    "            100*' ',\n",
    "            end='\\r'\n",
    "        )\n",
    "    \n",
    "    d_loss.append(d_loss_batch)\n",
    "    d_g_loss.append(d_g_loss_batch[0])\n",
    "    print('epoch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, d_loss[-1], d_g_loss[-1]), 100*' ')\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        samples = 9\n",
    "        z = np.random.normal(loc=0, scale=1, size=(samples, latent_dim))\n",
    "        labels = to_categorical(np.arange(0, 9).reshape(-1, 1), num_classes=9)\n",
    "        \n",
    "        x_fake = generator.predict([z, labels])\n",
    "        x_fake = np.clip(x_fake, -1, 1)\n",
    "        x_fake = (x_fake + 1) * 127\n",
    "        x_fake = np.round(x_fake).astype('uint8')\n",
    "\n",
    "        \n",
    "        fig = plt.figure(figsize=(8,8)) # rows*cols 행렬의 i번째 subplot 생성\n",
    "        rows = 3\n",
    "        cols = 3\n",
    "        i = 1\n",
    "        \n",
    "        for k in range(samples):\n",
    "            ax = fig.add_subplot(rows, cols, i)\n",
    "            ax.imshow(x_fake[k])\n",
    "            ax.set_title(class_names[k])\n",
    "            ax.set_xticks([]), ax.set_yticks([])\n",
    "            i += 1\n",
    "#         for k in range(samples):\n",
    "#             plt.figure(figsize=(10,10))\n",
    "#             plt.subplot(3, 3, k + 1, xticks=[], yticks=[])\n",
    "#             #plt.subplot(1, 9, k + 1, xticks=[], yticks=[])\n",
    "#             plt.imshow(x_fake[k])\n",
    "#             plt.title(class_names[k])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the metrics\n",
    "plt.plot(d_loss)\n",
    "plt.plot(d_g_loss)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Discriminator', 'Adversarial'], loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
